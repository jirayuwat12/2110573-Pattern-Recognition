{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qES4TJDxApaB"
      },
      "source": [
        "# Employee Attrition Prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SacSEoJ0nQuA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "guR7Z-AoA8wc"
      },
      "source": [
        "### read CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2uxs7gfBCUG"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('hr-employee-attrition-with-null.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ag-0B8i-BS-x"
      },
      "source": [
        "### Dataset statistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "9IOCh6I1BJ1y",
        "outputId": "6d1e3a16-53aa-462c-bfbf-2f2162000d57"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "ncRpzKlfBb48",
        "outputId": "d03ca374-c2ea-42eb-9922-dfa7d8e4b410"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NApae3ygBbEa"
      },
      "source": [
        "### Feature transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C3vuRArBKEe"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Attrition\"] == \"no\", \"Attrition\"] = 0.0\n",
        "df.loc[df[\"Attrition\"] == \"yes\", \"Attrition\"] = 1.0\n",
        "string_categorical_col = ['Department', 'Attrition', 'BusinessTravel', 'EducationField', 'Gender', 'JobRole',\n",
        "                              'MaritalStatus', 'Over18', 'OverTime']\n",
        "\n",
        "# ENCODE STRING COLUMNS TO CATEGORICAL COLUMNS\n",
        "for col in string_categorical_col:\n",
        "    # INSERT CODE HERE\n",
        "\n",
        "# HANDLE NULL NUMBERS\n",
        "# INSERT CODE HERE\n",
        "\n",
        "df = df.loc[:, ~df.columns.isin(['EmployeeNumber', 'Unnamed: 0', 'EmployeeCount', 'StandardHours', 'Over18'])]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q1sVXHQBGAQJ"
      },
      "source": [
        "###  Spliting data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train, df_test ="
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "edasSXrRHuFm"
      },
      "source": [
        "### Display histogram of each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_histogram(df, col_name, cls, n_bin = 40):\n",
        "    \n",
        "    # INSERT CODE HERE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6wH3pKLhLKw1"
      },
      "source": [
        "### T4. Observe the histogram for Age, MonthlyIncome and DistanceFromHome. How many bins have zero counts? Do you think this is a good discretization? Why?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BaLY_n3oOlGe"
      },
      "source": [
        "### T5. Can we use a Gaussian to estimate this histogram? Why? What about a Gaussian Mixture Model (GMM)?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JMbbl306QrEs"
      },
      "source": [
        "### T6. Now plot the histogram according to the method described above (with 10, 40, and 100 bins) and show 3 plots each for Age, MonthlyIncome, and DistanceFromHome. Which bin size is most sensible for each features? Why?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NlpUyIIuN0Hi"
      },
      "source": [
        "### T7. For the rest of the features, which one should be discretized in order to be modeled by histograms? What are the criteria for choosing whether we should discretize a feature or not? Answer this and discretize those features into 10 bins each. In other words, figure out the bin edge for each feature, then use digitize() to convert the features to discrete values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SJHkqbcSPwMW"
      },
      "source": [
        "### T8. What kind of distribution should we use to model histograms? (Answer a distribution name) What is the MLE for the likelihood distribution? (Describe how to do the MLE). Plot the likelihood distributions of MonthlyIncome, JobRole, HourlyRate, and MaritalStatus for different Attrition values."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "c_1EvThSWAwi"
      },
      "source": [
        "### T9. What is the prior distribution of the two classes?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JdEyB5Q7WSqI"
      },
      "source": [
        "### T10. If we use the current Naive Bayes with our current Maximum Likelihood Estimates, we will find that some P (x i |attrition) will be zero and will result in the entire product term to be zero. Propose a method to fix this problem."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "17O4iza4WX1X"
      },
      "source": [
        "### T11. Implement your Naive Bayes classifier. Use the learned distributions to classify the test set. Donâ€™t forget to allow your classifier to handle missing values in the test set. Report the overall Accuracy. Then, report the Precision, Recall, and F score for detecting attrition. See Lecture 1 for the definitions of each metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from SimpleBayesClassifier import SimpleBayesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_train = df_train.to_numpy()\n",
        "data_test = df_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = \n",
        "y_train = \n",
        "\n",
        "x_test = \n",
        "y_test = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleBayesClassifier(n_pos = , n_neg = )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_prior():\n",
        "    \"\"\"\n",
        "    This function designed to test the implementation of the prior probability calculation in a Naive Bayes classifier. \n",
        "    Specifically, it checks if the classifier correctly computes the prior probabilities for the \n",
        "    negative and positive classes based on given input counts.\n",
        "    \"\"\"\n",
        "    \n",
        "    # prior_neg = 5/(5 + 5) = 0.5 and # prior_pos = 5/(5 + 5) = 0.5\n",
        "    assert (SimpleBayesClassifier(5, 5).prior_pos, SimpleBayesClassifier(5, 5).prior_neg) == (0.5, 0.5)\n",
        "\n",
        "    assert (SimpleBayesClassifier(3, 5).prior_pos, SimpleBayesClassifier(3, 5).prior_neg) ==\n",
        "    assert (SimpleBayesClassifier(0, 1).prior_pos, SimpleBayesClassifier(0, 1).prior_neg) ==\n",
        "    assert (SimpleBayesClassifier(1, 0).prior_pos, SimpleBayesClassifier(1, 0).prior_neg) ==\n",
        "    \n",
        "check_prior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit_params(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_fit_params():\n",
        "\n",
        "    \"\"\"\n",
        "    This function is designed to test the fit_params method of a SimpleBayesClassifier. \n",
        "    This method is presumably responsible for computing parameters for a Naive Bayes classifier \n",
        "    based on the provided training data. The parameters in this context is bins and edges from each histogram.\n",
        "    \"\"\"\n",
        "\n",
        "    T = SimpleBayesClassifier(2, 2)\n",
        "    X_TRAIN_CASE_1 = np.array([\n",
        "        [0, 1, 2, 3],\n",
        "        [1, 2, 3, 4],\n",
        "        [2, 3, 4, 5],\n",
        "        [3, 4, 5, 6]\n",
        "    ])\n",
        "    Y_TRAIN_CASE_1 = np.array([0, 1, 0, 1])\n",
        "    STAY_PARAMS_1, LEAVE_PARAMS_1 = T.fit_params(X_TRAIN_CASE_1, Y_TRAIN_CASE_1)\n",
        "\n",
        "    print(\"STAY PARAMETERS\")\n",
        "    for f_idx in range(len(STAY_PARAMS_1)):\n",
        "        print(f\"Feature : {f_idx}\")\n",
        "        print(f\"BINS : {STAY_PARAMS_1[f_idx][0]}\")\n",
        "        print(f\"EDGES : {STAY_PARAMS_1[f_idx][1]}\")\n",
        "    print(\"\")    \n",
        "    print(\"LEAVE PARAMETERS\")\n",
        "    for f_idx in range(len(STAY_PARAMS_1)):\n",
        "        print(f\"Feature : {f_idx}\")\n",
        "        print(f\"BINS : {LEAVE_PARAMS_1[f_idx][0]}\")\n",
        "        print(f\"EDGES : {LEAVE_PARAMS_1[f_idx][1]}\")\n",
        "\n",
        "check_fit_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRoC5CEqopSR"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x = x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICDb3zONzk_r"
      },
      "outputs": [],
      "source": [
        "def evaluate(y_true, y_pred, show_result = True):\n",
        "\n",
        "  return accuracy, precision, recall, F1, fpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISYoqxHpF-3n",
        "outputId": "52dcd5c4-c1f2-417d-b34b-f96c66f136ed"
      },
      "outputs": [],
      "source": [
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WMAR2VHjFtRY"
      },
      "source": [
        "### T12. Use the learned distributions to classify the test set. Report the results using the same metric as the previous question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc1T-WVrFsyQ"
      },
      "outputs": [],
      "source": [
        "model.fit_gaussian_params(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_fit_gaussian_params():\n",
        "\n",
        "    \"\"\"\n",
        "    This function is designed to test the fit_gaussian_params method of a SimpleBayesClassifier. \n",
        "    This method is presumably responsible for computing parameters for a Naive Bayes classifier \n",
        "    based on the provided training data. The parameters in this context is mean and STD.\n",
        "    \"\"\"\n",
        "\n",
        "    T = SimpleBayesClassifier(2, 2)\n",
        "    X_TRAIN_CASE_1 = np.array([\n",
        "        [0, 1, 2, 3],\n",
        "        [1, 2, 3, 4],\n",
        "        [2, 3, 4, 5],\n",
        "        [3, 4, 5, 6]\n",
        "    ])\n",
        "    Y_TRAIN_CASE_1 = np.array([0, 1, 0, 1])\n",
        "    STAY_PARAMS_1, LEAVE_PARAMS_1 = T.fit_gaussian_params(X_TRAIN_CASE_1, Y_TRAIN_CASE_1)\n",
        "\n",
        "    print(\"STAY PARAMETERS\")\n",
        "    for f_idx in range(len(STAY_PARAMS_1)):\n",
        "        print(f\"Feature : {f_idx}\")\n",
        "        print(f\"Mean : {STAY_PARAMS_1[f_idx][0]}\")\n",
        "        print(f\"STD. : {STAY_PARAMS_1[f_idx][1]}\")\n",
        "    print(\"\")    \n",
        "    print(\"LEAVE PARAMETERS\")\n",
        "    for f_idx in range(len(STAY_PARAMS_1)):\n",
        "        print(f\"Feature : {f_idx}\")\n",
        "        print(f\"Mean : {LEAVE_PARAMS_1[f_idx][0]}\")\n",
        "        print(f\"STD. : {LEAVE_PARAMS_1[f_idx][1]}\")\n",
        "    \n",
        "check_fit_gaussian_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIB77js3Gq_N"
      },
      "outputs": [],
      "source": [
        "y_pred = model.gaussian_predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9klPSVfHROD",
        "outputId": "cda67822-6b24-44eb-fdee-63af89557f08"
      },
      "outputs": [],
      "source": [
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qvJd3MoWIR3c"
      },
      "source": [
        "### T13 : The random choice baseline is the accuracy if you make a random guess for each test sample. Give random guess (50% leaving, and 50% staying) to the test samples. Report the overall Accuracy. Then, report the Precision, Recall, and F score for attrition prediction using the random choice baseline."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-vbVLuCDIxNx"
      },
      "source": [
        "### T14. The majority rule is the accuracy if you use the most frequent class from the training set as the classification decision. Report the overall Accuracy. Then, report the Precision, Recall, and F score for attrition prediction using the majority rule baseline.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ6-fMVVJZcH"
      },
      "source": [
        "### T15. Compare the two baselines with your Naive Bayes classifier.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jkX76nMpKVMR"
      },
      "source": [
        "### T16. Use the following threshold values\n",
        "$ t = np.arange(-5,5,0.05) $\n",
        "### find the best accuracy, and F score (and the corresponding thresholds)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "df3wpyLtUMKl"
      },
      "source": [
        "### T17. Plot the RoC of your classifier."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ozvzlJyxZbH3"
      },
      "source": [
        "### T18. Change the number of discretization bins to 5. What happens to the RoC curve? Which discretization is better? The number of discretization bins can be considered as a hyperparameter, and must be chosen by comparing the final performance.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
